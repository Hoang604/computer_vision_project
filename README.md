# Image Super-Resolution with RRDBNet and Diffusion Models

## Overview

This project implements and explores advanced image super-resolution (SR) techniques using deep learning. It features multiple approaches, including:

1.  **Bicubic Interpolation**: A traditional baseline method.
2.  **RRDBNet (Residual-in-Residual Dense Block Network)**: A powerful deep learning model for direct super-resolution or as a component in more complex pipelines.
3.  **Conditional Diffusion Models (U-Net based)**:
    * **Predicting Residual from Bicubic Upscaling**: A U-Net model conditioned on RRDBNet features (extracted from the Low-Resolution input) learns to predict the residual between a High-Resolution (HR) image and its Bicubic upscaled Low-Resolution (LR) counterpart.
    * **Predicting Residual from RRDBNet Upscaling (Refinement)**: A U-Net model, conditioned on features from an RRDBNet (acting as a context extractor on the LR image), learns to predict the residual between the true HR image and an initial HR image generated by another (or the same) RRDBNet. This acts as a refinement step.

The project provides scripts for data preprocessing, model training, and inference for these different SR pipelines.

## Key Features

* **Multiple SR Pipelines**:
    * Bicubic interpolation.
    * Standalone RRDBNet for SR.
    * Diffusion model refining Bicubic upscaling (conditioned by RRDBNet features).
    * Diffusion model refining RRDBNet upscaling (conditioned by RRDBNet features).
* **Modular Design**: Code is organized into `src/` for core modules (data handling, model definitions, trainers) and `scripts/` for executable workflows (training, inference, preprocessing).
* **Flexible Training**:
    * Train RRDBNet for direct SR or residual prediction.
    * Train U-Net (Diffusion Model) to predict noise or 'v_prediction' for different residual targets.
    * Support for resuming training from checkpoints.
    * Configurable learning rate schedulers.
* **Data Handling**:
    * `ImageDataset` (`src/data_handling/dataset.py`): For general image loading, creating LR, Bicubic upscaled, and residual (HR - Bicubic) images on-the-fly.
    * `ImageDatasetRRDB` (`src/data_handling/dataset.py`): For loading preprocessed data, including LR images, HR images, RRDB-upscaled images, and (if preprocessed) extracted LR features.
    * Preprocessing scripts in `src/data_handling/` to generate datasets for different training pipelines.
* **Inference Scripts**: Ready-to-use scripts in `scripts/` to apply trained models to new images.
* **TensorBoard Logging**: Integrated for monitoring training progress.

## Implemented Models and Techniques

1.  **Bicubic Interpolation (`src/utils/bicubic.py`)**
    * A standard interpolation algorithm used for baseline comparison and as an initial upscaling step in some pipelines.
    * The `upscale_image` function provides flexible input/output handling.

2.  **RRDBNet (`src/diffusion_modules/rrdb.py`, `src/trainers/rrdb_trainer.py`, `scripts/train_rrdb.py`, `scripts/rrdb_infer.py`)**
    * Architecture (`src/diffusion_modules/rrdb.py`): Based on Residual-in-Residual Dense Blocks.
    * Training Logic (`src/trainers/rrdb_trainer.py`): Defines the `BasicRRDBNetTrainer` class.
    * Main Training Script (`scripts/train_rrdb.py`): Uses `BasicRRDBNetTrainer` to train RRDBNet. Can be trained to directly predict the HR image or to predict the residual (HR - Bicubic upscaled LR).
    * Inference (`scripts/rrdb_infer.py`): Applies a trained RRDBNet for super-resolution.
    * Role: Can act as a standalone SR model, a base SR model for diffusion refinement, or a feature extractor for conditioning diffusion models.

3.  **Diffusion Models (U-Net based on DDPM/DDIM)**
    * Core U-Net Architecture (`src/diffusion_modules/unet.py`): A U-Net model with optional attention mechanisms (`src/diffusion_modules/attention_block.py`) and ResNet blocks, conditioned on features. Other components like `SinusoidalPosEmb` are in `src/utils/network_comopents.py`.
    * Training Logic (`src/trainers/diffusion_trainer.py`): Defines the `DiffusionTrainer` class.
        * `DiffusionTrainer`: Handles the DDPM/DDIM training loop, supporting "noise" and "v_prediction" modes.
        * `ResidualGenerator` (within `src/trainers/diffusion_trainer.py`): Used during inference (sampling) with a DDIM scheduler.
    * **Pipeline 1: Refining Bicubic Upscaling**
        * Training (`scripts/train_diffusion.py`):
            * The U-Net learns to predict the residual (HR - Bicubic upscaled LR) or the noise to reverse the noising of this residual.
            * Conditioned on features extracted by an RRDBNet from the LR image (on-the-fly).
            * Uses `ImageDataset` for on-the-fly data generation (LR, Bicubic HR, HR - Bicubic residual).
        * Inference:
            * The provided `scripts/diffusion_infer.py` is primarily set up for Pipeline 2 (refining RRDBNet outputs using `ImageDatasetRRDB`).
            * To perform inference for a model trained by `scripts/train_diffusion.py` (i.e., refining Bicubic on-the-fly), you would need to:
                * Adapt `scripts/diffusion_infer.py` to take an LR image, perform Bicubic upscaling, extract RRDBNet features from LR, and then use the U-Net to predict and add the residual to the Bicubic upscaled image.
                * Alternatively, modify a script like `scripts/rrdb_infer.py` to also load the U-Net and apply the diffusion-based refinement after Bicubic upscaling.
    * **Pipeline 2: Refining RRDBNet Upscaling (Predicting RRDB Residual)**
        * Data Preprocessing (`src/data_handling/preprocess_data_with_rrdb.py`):
            * Generates a dataset where each sample includes: LR image, HR image, HR image upscaled by a base RRDBNet. Note: The current `preprocess_data_with_rrdb.py` script in your upload (`preprocess_images_batched_rrdb_no_features`) saves LR, HR original, and HR_RRDB_upscaled, but *does not* pre-save LR features. LR features are extracted on-the-fly by the `context_extractor_model` during training with `scripts/train_diffusion_predict_rrdb_residual.py` and inference with `scripts/diffusion_infer.py`.
        * Training (`scripts/train_diffusion_predict_rrdb_residual.py`):
            * The U-Net learns to predict the residual (True HR - RRDB-upscaled HR) or the noise to reverse the noising of this residual.
            * Conditioned on features extracted on-the-fly by a context RRDBNet from the LR image.
            * Uses `ImageDatasetRRDB` to load preprocessed data (LR, HR_RRDB_upscaled, HR_Original).
        * Inference (`scripts/diffusion_infer.py`):
            * This script is suited for this pipeline.
            * It loads preprocessed data (LR, HR_RRDB_upscaled, etc.) using `ImageDatasetRRDB`.
            * An RRDBNet (context extractor) extracts features from the LR image on-the-fly.
            * The U-Net, conditioned on these features, predicts the residual.
            * This predicted residual is added to the RRDB-upscaled image (loaded as `up_lr_img` which is actually `hr_rrdb_upscaled` from the dataset).

## Directory Structure

```
computer_vision_project/
│
├── data/                             # (User-created) Root directory for raw HR images
│   └── my_hr_images/                 # (User-created) Example subdirectory with HR images (e.g., for train, validation)
│
├── preprocessed_data/                # (Auto-generated by preprocessing scripts)
│   ├── bicubic_processed_train/      # Example output from preprocess_data_with_bicubic.py
│   │   ├── hr_original/              # Stores original HR images as .pt
│   │   ├── lr/                       # Stores LR images as .pt
│   │   └── hr_bicubic_upscaled/      # Stores HR images upscaled by Bicubic as .pt
│   ├── rrdb_refined_train/           # Example output from preprocess_data_with_rrdb.py
│   │   ├── hr_original/              # Stores original HR images as .pt
│   │   ├── lr/                       # Stores LR images as .pt
│   │   └── hr_rrdb_upscaled/         # Stores HR images upscaled by RRDBNet as .pt
│   │                                 # (Note: lr_features are NOT saved by the current preprocess_data_with_rrdb.py, extracted on-the-fly)
│   └── ...                           # Similar structure for validation splits
│
├── inference_results/                # (User-created or auto-generated) For saving inference outputs
│
├── logs_rrdb/                        # (Auto-generated) TensorBoard logs for RRDBNet training
├── checkpoints_rrdb/                 # (Auto-generated) Checkpoints for RRDBNet training
│
├── logs_diffusion_bicubic/           # (Auto-generated) TensorBoard logs for Diffusion (refining bicubic)
├── checkpoints_diffusion_bicubic/    # (Auto-generated) Checkpoints for Diffusion (refining bicubic)
│
├── logs_diffusion_rrdb_residual/     # (Auto-generated) TensorBoard logs for Diffusion (predicting RRDB residual)
├── checkpoints_diffusion_rrdb_residual/ # (Auto-generated) Checkpoints for Diffusion (predicting RRDB residual)
│
├── src/
│   ├── data_handling/
│   │   ├── dataset.py                # Defines ImageDataset, ImageDatasetRRDB
│   │   ├── preprocess_data_with_bicubic.py # Preprocesses for Bicubic-based pipelines
│   │   └── preprocess_data_with_rrdb.py  # Preprocesses for RRDB-refinement pipeline
│   │
│   ├── diffusion_modules/
│   │   ├── attention_block.py        # Transformer/Attention blocks for U-Net
│   │   ├── rrdb.py                   # Defines RRDBNet architecture
│   │   └── unet.py                   # Defines U-Net architecture
│   │
│   ├── trainers/
│   │   ├── diffusion_trainer.py      # Defines DiffusionTrainer class
│   │   └── rrdb_trainer.py           # Defines BasicRRDBNetTrainer class
│   │
│   └── utils/
│       ├── bicubic.py                # Bicubic upscaling utility
│       └── network_comopents.py      # Auxiliary network components (SinusoidalPosEmb, ResnetBlock, etc.)
│
├── scripts/
│   ├── diffusion_infer.py            # Inference for Diffusion Model (refining RRDBNet output)
│   ├── rrdb_infer.py                 # Inference for standalone RRDBNet
│   ├── train_diffusion.py            # Main script to train Diffusion Model (refining Bicubic)
│   ├── train_diffusion_predict_rrdb_residual.py # Main script to train Diffusion Model (refining RRDBNet)
│   └── train_rrdb.py                 # Main script to train RRDBNet
│
├── requirements.txt                  # Python dependencies
└── README.md                         # This file
```

## Installation

1.  **Clone the repository (if applicable):**
    ```bash
    git clone [https://github.com/Hoang604/computer_vision_project.git](https://github.com/Hoang604/computer_vision_project.git)
    cd computer_vision_project
    ```

2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Linux/macOS
    # venv\Scripts\activate    # On Windows
    ```

    **Alternatively, using Conda:**
    ```bash
    conda create -n myenv python=3.9 # Or your preferred Python version
    conda activate myenv
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *Note*: Ensure your PyTorch version is compatible with your CUDA version if using a GPU. The `requirements.txt` specifies `torch` and `torchvision`.

## Data Preparation

### Option 1: On-the-fly Processing (for `scripts/train_diffusion.py`)

* Place your high-resolution (HR) images in a directory (e.g., `data/my_hr_images/`).
* The `ImageDataset` (defined in `src/data_handling/dataset.py`) used by `scripts/train_diffusion.py` will handle creating Low-Resolution (LR) images, Bicubic upscaled images, and the residual (HR - Bicubic upscaled) during data loading.

### Option 2: Preprocessing for Advanced Pipelines

#### a) Preprocessing with Bicubic (using `src/data_handling/preprocess_data_with_bicubic.py`)
This script creates a dataset suitable for pipelines that might start with Bicubic upscaling or need these specific tensor components.
It saves:
    * Original HR images (resized to `img_size`).
    * LR images.
    * HR images upscaled from LR using Bicubic interpolation.

**Example Usage:**
```bash
python -m src.data_handling.preprocess_data_with_bicubic \
    --input_dir data/my_hr_images \
    --output_dir preprocessed_data/bicubic_processed_train \
    --img_size 160 \
    --downscale_factor 4 \
    --device cuda:0
```

#### b) Preprocessing with RRDBNet (using `src/data_handling/preprocess_data_with_rrdb.py`)
This script is crucial for the "Diffusion Model Refining RRDBNet Upscaling" pipeline (`scripts/train_diffusion_predict_rrdb_residual.py` and `scripts/diffusion_infer.py`).
The current version (`preprocess_images_batched_rrdb_no_features` function within the script) saves:
    * Original HR images (resized to `img_size`).
    * LR images.
    * HR images upscaled from LR using a specified RRDBNet (the "base SR" model).
It **does not** pre-save LR features; these are extracted on-the-fly during training/inference.

**Example Usage:**
```bash
python -m src.data_handling.preprocess_data_with_rrdb \
    --input_dir data/my_hr_images/train \
    --output_dir preprocessed_data/rrdb_refined_train \
    --img_size 160 \
    --downscale_factor 4 \
    --rrdb_weights_path_for_upscaling checkpoints_rrdb/your_rrdb_model_for_upscaling/rrdb_model_best.pth \
    --rrdb_num_feat 64 \
    --rrdb_num_block 17 \
    --rrdb_gc 32 \
    --batch_size 32 \
    --device cuda:0
```
* `--rrdb_weights_path_for_upscaling`: Path to the pre-trained RRDBNet model that will be used for upscaling the LR image (to create `hr_rrdb_upscaled`). The configuration arguments (`--rrdb_num_feat`, `--rrdb_num_block`, `--rrdb_gc`) must match this loaded model.

Create separate preprocessed datasets for training and validation by pointing `--input_dir` and `--output_dir` accordingly.

## How to Train

### 1. Train RRDBNet (Standalone or as a component)

Use `scripts/train_rrdb.py`. This RRDBNet can be used for direct SR, as a base upscaler for the diffusion refinement pipeline, or as a context extractor for conditioning the U-Net.

**Example Command:**
```bash
python -m scripts.train_rrdb \
    --image_folder data/my_hr_images/train \
    --val_image_folder data/my_hr_images/validation \
    --img_size 160 \
    --downscale_factor 4 \
    --rrdb_num_feat 64 \
    --rrdb_num_block 17 \
    --rrdb_gc 32 \
    --epochs 100 \
    --batch_size 32 \
    --val_batch_size 32 \
    --accumulation_steps 4 \
    --learning_rate 1e-4 \
    --scheduler_type CosineAnnealingLR \
    --cosine_t_max 100 \
    --device cuda:0 \
    --exp_name rrdb_model_nb17_nf64 \
    --base_log_dir ./logs_rrdb \
    --base_checkpoint_dir ./checkpoints_rrdb \
    --save_every_n_epochs 10
    # --predict_residual  # Add this flag to train RRDBNet to predict (HR - Bicubic upscaled LR)
    # --weights_path checkpoints_rrdb/some_experiment/rrdb_model_epoch_XX.pth # To resume training
```
**Key Arguments for `scripts/train_rrdb.py`:** (Refer to the script's `argparse` for full details)
* `--image_folder`, `--val_image_folder`: Paths to HR image data (expects preprocessed bicubic data if using `ImageDatasetBicubic`).
* Model architecture: `--rrdb_num_feat`, `--rrdb_num_block`, `--rrdb_gc`.
* Training loop: `--epochs`, `--batch_size`, `--accumulation_steps`, `--learning_rate`.
* Scheduler: `--scheduler_type` and its related arguments (e.g., `--cosine_t_max`).
* Logging/Saving: `--exp_name`, `--base_log_dir`, `--base_checkpoint_dir`, `--weights_path` (for resuming).
* `--predict_residual`: If set, trains RRDBNet to predict the residual (HR - Bicubic upscaled LR).

### 2. Train Diffusion Model (U-Net)

#### Pipeline A: Refining Bicubic Upscaling (using `scripts/train_diffusion.py`)

This pipeline trains a U-Net to predict the residual (HR - Bicubic upscaled LR) or the noise to reverse the noising of this residual. It's conditioned on features from an RRDBNet, extracted on-the-fly from LR images. Data (LR, Bicubic HR, HR-Bicubic residual) is generated on-the-fly by `ImageDataset`.

**Prerequisite**: A pre-trained RRDBNet model (e.g., from step 1) to act as the context extractor.

**Example Command:**
```bash
python -m scripts.train_diffusion \
    --image_folder data/my_hr_images/train \
    --img_size 160 \
    --downscale_factor 4 \
    --epochs 100 \
    --batch_size 8 \
    --accumulation_steps 4 \
    --learning_rate 1e-4 \
    --scheduler_type cosineannealinglr \
    --cosine_t_max_epochs 100 \
    --device cuda:0 \
    --diffusion_mode noise \
    --timesteps 1000 \
    --unet_base_dim 64 \
    --unet_dim_mults 1 2 4 8 \
    --use_attention \
    --rrdb_weights_path checkpoints_rrdb/rrdb_context_extractor/rrdb_model_best.pth \
    --number_of_rrdb_blocks 17 \
    --rrdb_num_feat 64 \
    --rrdb_gc 32 \
    --base_log_dir ./logs_diffusion_bicubic \
    --base_checkpoint_dir ./checkpoints_diffusion_bicubic \
    --exp_name diffusion_refine_bicubic
    # --weights_path_unet checkpoints_diffusion_bicubic/some_exp/diffusion_model_best.pth # To resume U-Net training
```
**Key Arguments for `scripts/train_diffusion.py`:** (Refer to the script's `argparse` for full details)
* Dataset: `--image_folder`, `--img_size`, `--downscale_factor`.
* U-Net: `--unet_base_dim`, `--unet_dim_mults`, `--use_attention`.
* Context RRDBNet: `--rrdb_weights_path` (path to pre-trained RRDBNet for context), and its configuration (`--number_of_rrdb_blocks`, `--rrdb_num_feat`, `--rrdb_gc`) which **must match** the loaded RRDBNet.
* `--context_type`: Set to `LR` (default) as features are extracted from the LR image.

#### Pipeline B: Refining RRDBNet Upscaling (using `scripts/train_diffusion_predict_rrdb_residual.py`)

This pipeline trains a U-Net to predict the residual (True HR - RRDB-upscaled HR). It uses preprocessed data (LR, HR_RRDB_upscaled, HR_Original) generated by `src/data_handling/preprocess_data_with_rrdb.py`. Features from LR images are extracted on-the-fly by a context RRDBNet.

**Prerequisites**:
1.  Preprocessed data created by `src/data_handling/preprocess_data_with_rrdb.py`.
2.  A pre-trained RRDBNet model to act as the on-the-fly context extractor. Its configuration must be provided to the training script.

**Example Command:**
```bash
python -m scripts.train_diffusion_predict_rrdb_residual \
    --preprocessed_data_folder preprocessed_data/rrdb_refined_train \
    --val_preprocessed_data_folder preprocessed_data/rrdb_refined_validation \
    --img_size 160 \
    --downscale_factor 4 \
    --apply_hflip \
    --epochs 100 \
    --batch_size 8 \
    --accumulation_steps 4 \
    --learning_rate 1e-4 \
    --scheduler_type cosineannealinglr \
    --cosine_t_max_epochs 100 \
    --device cuda:0 \
    --diffusion_mode noise \
    --timesteps 1000 \
    --unet_base_dim 64 \
    --unet_dim_mults 1 2 4 8 \
    --use_attention \
    --rrdb_weights_path_context_extractor checkpoints_rrdb/context_extractor_rrdb/rrdb_model_best.pth \
    --rrdb_num_block_context 17 \
    --rrdb_num_feat_context 64 \
    --rrdb_gc_context 32 \
    --base_log_dir ./logs_diffusion_rrdb_residual \
    --base_checkpoint_dir ./checkpoints_diffusion_rrdb_residual \
    --exp_name diffusion_refine_rrdb
    # --weights_path_unet checkpoints_diffusion_rrdb_residual/some_exp/diffusion_model_best.pth # To resume U-Net training
```
**Key Arguments for `scripts/train_diffusion_predict_rrdb_residual.py`:** (Refer to script's `argparse`)
* Dataset: `--preprocessed_data_folder`, `--val_preprocessed_data_folder`.
* Context RRDBNet (for on-the-fly feature extraction): `--rrdb_weights_path_context_extractor`, and its config (`--rrdb_num_block_context`, `--rrdb_num_feat_context`, `--rrdb_gc_context`). These define the architecture of the U-Net's conditioning projection and **must match the context RRDBNet being loaded**.
* `--context`: Set to `LR` (default) for the `DiffusionTrainer`'s internal logic.

## How to Perform Inference

### 1. Inference with Standalone RRDBNet

Use `scripts/rrdb_infer.py`.
**Modify the script `scripts/rrdb_infer.py` internally to set:**
* `model_path`: Path to your trained RRDBNet checkpoint (`.pth`).
* `config`: Dictionary with the RRDBNet configuration (must match training).
* `dataset`: Path to your test images (or modify `ImageDataset` initialization).
* `predict_residual`: Set to `True` if the RRDBNet was trained to predict residuals, `False` otherwise.

**Run:**
```bash
python -m scripts.rrdb_infer
```
The script will load a random image, perform inference, and plot/show the results.

### 2. Inference with Diffusion Model (Refining RRDBNet Output)

Use `scripts/diffusion_infer.py`. This script is designed to work with data preprocessed by `src/data_handling/preprocess_data_with_rrdb.py` (using `ImageDatasetRRDB`). It takes an LR image from this dataset, uses an RRDBNet (context extractor) to get features on-the-fly, and then a U-Net predicts the residual to refine the pre-upscaled RRDB image (also from the dataset).

**Modify `scripts/diffusion_infer.py` internally to set:**
* `rrdb_path`: Path to the RRDBNet checkpoint (used as context extractor). Its configuration (`config` variable in the script) must match the loaded model.
* `unet_path`: Path to the trained U-Net checkpoint. The U-Net instantiation (`unet = Unet(...)`) must match the trained model's architecture (e.g., `use_attention`, `rrdb_num_blocks` for conditioning which should match context extractor's `num_block`).
* `img_folder`: Path to the preprocessed data directory (e.g., `preprocessed_data/rrdb_refined_test/`) that `ImageDatasetRRDB` will use.
* `img_size`: Must match the data.
* `predict_mode` for `ResidualGenerator` must match how the U-Net was trained (`noise` or `v_prediction`).

**Run (after script modification):**
```bash
python -m scripts.diffusion_infer
```
The script will load a random sample, perform inference, and plot/save the results.

**Note on Refining Bicubic Upscaling (Inference):**
As mentioned in "Implemented Models and Techniques", `scripts/diffusion_infer.py` is primarily for refining RRDB outputs. If you trained a model using `scripts/train_diffusion.py` (which refines Bicubic upscaling on-the-fly), you'll need to adapt an inference script. This would involve:
1. Loading an LR image.
2. Performing Bicubic upscaling.
3. Using a context RRDBNet to extract features from the LR image.
4. Using the U-Net (trained with `scripts/train_diffusion.py`) to predict the residual based on the Bicubic upscaled image and LR features.
5. Adding this residual to the Bicubic upscaled image.

## Dependencies

Key Python libraries are listed in `requirements.txt`. Ensure they are installed, for example:
```
diffusers
matplotlib
numpy
opencv-python
Pillow
torch
torchvision
tqdm
# tensorboard (usually comes with PyTorch or can be installed separately: pip install tensorboard)
```

## Future Work / TODO

* Implement quantitative evaluation metrics (PSNR, SSIM, LPIPS).
* Experiment with different noise schedulers and sampling methods for diffusion models.
* Explore more advanced U-Net architectures or conditioning mechanisms.
* Optimize inference speed (e.g., model quantization, ONNX conversion).
* Develop a more user-friendly interface for inference (e.g., Gradio or Streamlit app).
* Investigate alternative feature extraction networks for conditioning.

## Acknowledgements

* This project builds upon concepts from prominent research in super-resolution and diffusion models.
* Inspired by the paper: "SRDiff: Single Image Super-Resolution with Diffusion Probabilistic Models" by Li, H., Liu, Y., Zhan, F., Lu, S., Xing, E. P., & Miao, C. (2021). ([arXiv:2104.14951](https://arxiv.org/pdf/2104.14951.pdf))
