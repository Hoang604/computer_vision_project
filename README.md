# Image Super-Resolution with RRDBNet and Diffusion Models

## Overview

This project implements and explores advanced image super-resolution (SR) techniques using deep learning. It features multiple approaches, including:

1.  **Bicubic Interpolation**: A traditional baseline method.
2.  **RRDBNet (Residual-in-Residual Dense Block Network)**: A powerful deep learning model for direct super-resolution or as a component in more complex pipelines.
3.  **Conditional Diffusion Models (U-Net based)**:
    * **Predicting Residual from Bicubic Upscaling**: A U-Net model conditioned on RRDBNet features (extracted from the Low-Resolution input) learns to predict the residual between a High-Resolution (HR) image and its Bicubic upscaled Low-Resolution (LR) counterpart.
    * **Predicting Residual from RRDBNet Upscaling (Refinement)**: A U-Net model, conditioned on features from an RRDBNet (acting as a context extractor on the LR image), learns to predict the residual between the true HR image and an initial HR image generated by another (or the same) RRDBNet. This acts as a refinement step.

The project provides scripts for data preprocessing, model training, and inference for these different SR pipelines.

## Key Features

* **Multiple SR Pipelines**:
    * Bicubic interpolation.
    * Standalone RRDBNet for SR.
    * Diffusion model refining Bicubic upscaling (conditioned by RRDBNet features).
    * Diffusion model refining RRDBNet upscaling (conditioned by RRDBNet features).
* **Modular Design**: Separate scripts for training, inference, and preprocessing.
* **Flexible Training**:
    * Train RRDBNet for direct SR or residual prediction.
    * Train U-Net (Diffusion Model) to predict noise or 'v_prediction' for different residual targets.
    * Support for resuming training from checkpoints.
    * Configurable learning rate schedulers.
* **Data Handling**:
    * `ImageDataset`: For general image loading, creating LR, Bicubic upscaled, and residual (HR - Bicubic) images on-the-fly.
    * `ImageDatasetRRDB`: For loading preprocessed data, including LR images, HR images, RRDB-upscaled images, and extracted LR features.
    * Preprocessing scripts to generate datasets for different training pipelines.
* **Inference Scripts**: Ready-to-use scripts to apply trained models to new images.
* **TensorBoard Logging**: Integrated for monitoring training progress.

## Implemented Models and Techniques

1.  **Bicubic Interpolation (`bicubic.py`)**
    * A standard interpolation algorithm used for baseline comparison and as an initial upscaling step in some pipelines.
    * The `upscale_image` function provides flexible input/output handling.

2.  **RRDBNet (`diffusion_modules.py`, `rrdb_trainer.py`, `train_rrdb.py`, `rrdb_infer.py`)**
    * Architecture: Based on Residual-in-Residual Dense Blocks.
    * Training (`train_rrdb.py`): Can be trained to directly predict the HR image or to predict the residual (HR - Bicubic upscaled LR).
    * Inference (`rrdb_infer.py`): Applies a trained RRDBNet for super-resolution.
    * Role: Can act as a standalone SR model, a base SR model for diffusion refinement, or a feature extractor for conditioning diffusion models.

3.  **Diffusion Models (U-Net based on DDPM/DDIM)**
    * Core Architecture (`diffusion_modules.py`): A U-Net model with optional attention mechanisms and ResNet blocks, conditioned on features.
    * Training Logic (`diffusion_trainer.py`):
        * `DiffusionTrainer`: Handles the DDPM/DDIM training loop, supporting "noise" and "v_prediction" modes.
        * `ResidualGenerator`: Used during inference (sampling) with a DDIM scheduler.
    * **Pipeline 1: Refining Bicubic Upscaling**
        * Training (`train_diffusion.py`):
            * The U-Net learns to predict the residual (HR - Bicubic upscaled LR) or the noise to reverse the noising of this residual.
            * Conditioned on features extracted by an RRDBNet from the LR image.
            * Uses `ImageDataset` for on-the-fly data generation.
        * Inference (`diffusion_infer.py`):
            * Takes an LR image, uses RRDBNet for feature extraction and initial Bicubic upscaling (implicitly, as the model was trained on this residual).
            * U-Net predicts the residual, which is added to the Bicubic upscaled image.
            * *(Note: The provided `diffusion_infer.py` seems to use RRDBNet for the base upscaling and then adds the diffusion residual. This might be a slight deviation from a pure "refining Bicubic" setup if the RRDBNet is powerful. The training in `train_diffusion.py` prepares residuals against Bicubic.)*
    * **Pipeline 2: Refining RRDBNet Upscaling (Predicting RRDB Residual)**
        * Data Preprocessing (`utils/preprocess_data_with_rrdb.py`):
            * Generates a dataset where each sample includes: LR image, HR image, HR image upscaled by a base RRDBNet, and features extracted from the LR image by a context RRDBNet.
        * Training (`train_diffusion_predict_rrdb_residual.py`):
            * The U-Net learns to predict the residual (True HR - RRDB-upscaled HR) or the noise to reverse the noising of this residual.
            * Conditioned on features extracted by an RRDBNet (context extractor) from the LR image.
            * Uses `ImageDatasetRRDB` to load preprocessed data.
        * Inference (`diffusion_infer_with_rrdb_residual.py`):
            * Takes an LR image.
            * A base RRDBNet generates an initial HR image.
            * A context RRDBNet extracts features from the LR image.
            * The U-Net, conditioned on these features, predicts the residual.
            * This predicted residual is added to the base RRDBNet's HR output for refinement.

## Directory Structure (Key Files & Expected User-Created Directories)

```
computer_vision_project/
│
├── data/                             # (User-created) Root directory for raw HR images
│   └── my_hr_images/                 # (User-created) Example subdirectory with HR images
│
├── preprocessed_data/                # (Auto-generated by preprocessing scripts)
│   ├── train/                        # Example for training split
│   │   ├── hr_original/              # Stores original HR images as .pt
│   │   ├── lr/                       # Stores LR images as .pt
│   │   ├── hr_rrdb_upscaled/         # Stores HR images upscaled by RRDBNet (from preprocess_data_with_rrdb.py) as .pt
│   │   └── lr_features/              # Stores extracted LR features as .pt (list of tensors)
│   └── validation/                   # Example for validation split (similar structure)
│
├── bicubic_output/                   # (Auto-generated by bicubic.py if saving output)
├── inference_results/                # (User-created or auto-generated) For saving inference outputs
│
├── logs_rrdb/                        # (Auto-generated) TensorBoard logs for RRDBNet training
├── checkpoints_rrdb/                 # (Auto-generated) Checkpoints for RRDBNet training
├── logs_diffusion_v2/                # (Auto-generated) TensorBoard logs for Diffusion Model (predicting RRDB residual)
├── checkpoints_diffusion_v2/         # (Auto-generated) Checkpoints for Diffusion Model (predicting RRDB residual)
├── cv_logs_diffusion/                # (Auto-generated, possibly from older train_diffusion.py) Logs for Diffusion (refining bicubic)
├── cv_checkpoints_diffusion/         # (Auto-generated, possibly from older train_diffusion.py) Checkpoints for Diffusion (refining bicubic)
│
├── bicubic.py                        # Bicubic upscaling script
│
├── diffusion_modules.py              # Defines U-Net, RRDBNet, and other network components
├── diffusion_trainer.py              # Training logic for Diffusion Models (U-Net)
├── diffusion_infer.py                # Inference for Diffusion Model (likely refining Bicubic/RRDB base)
├── diffusion_infer_with_rrdb_residual.py # Inference for Diffusion Model refining an RRDBNet output
│
├── rrdb_trainer.py                   # Training logic for RRDBNet
├── rrdb_infer.py                     # Inference for standalone RRDBNet
│
├── train_rrdb.py                     # Main script to train RRDBNet
├── train_diffusion.py                # Main script to train Diffusion Model (refining Bicubic, using ImageDataset)
├── train_diffusion_predict_rrdb_residual.py # Main script to train Diffusion Model (refining RRDBNet, using ImageDatasetRRDB)
│
├── utils/
│   ├── dataset.py                    # Defines ImageDataset and ImageDatasetRRDB
│   ├── network_comopents.py          # Auxiliary network components (SinusoidalPosEmb, ResnetBlock, etc.)
│   ├── preprocess_data_with_bicubic.py # Preprocesses data for Bicubic-based pipelines (saves LR, HR, Bicubic HR)
│   └── preprocess_data_with_rrdb.py  # Preprocesses data for RRDB-refinement pipeline (saves LR, HR, RRDB HR, LR features)
│
├── requirements.txt                  # Python dependencies
└── README.md                         # This file
```

## Installation

1.  **Clone the repository (if applicable):**
    ```bash
    git clone <your-repo-url>
    cd computer_vision_project
    ```

2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Linux/macOS
    # venv\Scripts\activate    # On Windows
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *Note*: Ensure your PyTorch version is compatible with your CUDA version if using a GPU. The `requirements.txt` specifies `torch==2.7.0` and `torchvision==0.22.0`.

## Data Preparation

### Option 1: On-the-fly Processing (for `train_diffusion.py`)

* Place your high-resolution (HR) images in a directory (e.g., `data/my_hr_images/`).
* The `ImageDataset` used by `train_diffusion.py` will handle creating Low-Resolution (LR) images, Bicubic upscaled images, and the residual (HR - Bicubic upscaled) during data loading.

### Option 2: Preprocessing for Advanced Pipelines

#### a) Preprocessing with Bicubic (using `utils/preprocess_data_with_bicubic.py`)
This script creates a dataset suitable for pipelines that might start with Bicubic upscaling.
It saves:
    * Original HR images (resized to `img_size`).
    * LR images.
    * HR images upscaled from LR using Bicubic interpolation.

**Example Usage:**
```bash
python utils/preprocess_data_with_bicubic.py \
    --input_dir data/my_hr_images \
    --output_dir preprocessed_data/bicubic_processed_train \
    --img_size 160 \
    --downscale_factor 4 \
    --device cuda:0
```

#### b) Preprocessing with RRDBNet (using `utils/preprocess_data_with_rrdb.py`)
This script is crucial for the "Diffusion Model Refining RRDBNet Upscaling" pipeline.
It saves:
    * Original HR images (resized to `img_size`).
    * LR images.
    * HR images upscaled from LR using a specified RRDBNet (the "base SR" model).
    * Features extracted from the LR images using another (or the same) RRDBNet (the "context extractor" model).

**Example Usage:**
```bash
python utils/preprocess_data_with_rrdb.py \
    --input_dir data/my_hr_images/train \
    --output_dir preprocessed_data/rrdb_refined_train \
    --img_size 160 \
    --downscale_factor 4 \
    --rrdb_weights_path checkpoints_rrdb/your_rrdb_model/rrdb_model_best.pth \
    --rrdb_num_feat 64 \
    --rrdb_num_block 17 \
    --rrdb_gc 32 \
    --batch_size 32 \
    --device cuda:0
```
* `--rrdb_weights_path`: Path to the pre-trained RRDBNet model that will be used for BOTH upscaling the LR image (to create `hr_rrdb_upscaled`) AND extracting features from the LR image (to create `lr_features`). The configuration arguments (`--rrdb_num_feat`, `--rrdb_num_block`, `--rrdb_gc`) must match this loaded model.

Create separate preprocessed datasets for training and validation by pointing `--input_dir` and `--output_dir` accordingly.

## How to Train

### 1. Train RRDBNet (Standalone or as a component)

Use `train_rrdb.py`. This RRDBNet can be used for direct SR, as a base upscaler for the diffusion refinement pipeline, or as a context extractor for conditioning the U-Net.

**Example Command:**
```bash
python train_rrdb.py \
    --image_folder data/my_hr_images/train \
    --val_image_folder data/my_hr_images/validation \
    --img_size 160 \
    --downscale_factor 4 \
    --rrdb_num_feat 64 \
    --rrdb_num_block 17 \
    --rrdb_gc 32 \
    --epochs 100 \
    --batch_size 32 \
    --val_batch_size 32 \
    --accumulation_steps 4 \
    --learning_rate 1e-4 \
    --scheduler_type CosineAnnealingLR \
    --cosine_t_max 100 \
    --device cuda:0 \
    --exp_name rrdb_model_nb17_nf64 \
    --base_log_dir ./logs_rrdb \
    --base_checkpoint_dir ./checkpoints_rrdb \
    --save_every_n_epochs 10
    # --predict_residual  # Add this flag to train RRDBNet to predict (HR - Bicubic upscaled LR)
    # --weights_path checkpoints_rrdb/some_experiment/rrdb_model_epoch_XX.pth # To resume training
```
**Key Arguments for `train_rrdb.py`:**
* `--image_folder`: Path to training HR images.
* `--val_image_folder`: Path to validation HR images (optional).
* `--img_size`, `--downscale_factor`: Dataset parameters.
* `--rrdb_num_feat`, `--rrdb_num_block`, `--rrdb_gc`: RRDBNet architecture.
* `--epochs`, `--batch_size`, `--accumulation_steps`, `--learning_rate`: Training loop parameters.
* `--scheduler_type`: Type of learning rate scheduler (e.g., `none`, `StepLR`, `CosineAnnealingLR`, `CosineAnnealingWarmRestarts`, `ReduceLROnPlateau`).
    * Additional arguments are available for each scheduler type (e.g., `--cosine_t_max`, `--step_lr_step_size`).
* `--exp_name`: Experiment name for logs and checkpoints.
* `--weights_path`: Path to a checkpoint to resume training.
* `--predict_residual`: If set, trains RRDBNet to predict the residual (HR - Bicubic upscaled LR).

### 2. Train Diffusion Model (U-Net)

#### Pipeline A: Refining Bicubic Upscaling (using `train_diffusion.py`)

This pipeline trains a U-Net to predict the residual (HR - Bicubic upscaled LR) or the noise to reverse the noising of this residual. It's conditioned on features from an RRDBNet.

**Prerequisite**: A pre-trained RRDBNet model (e.g., from step 1) to act as the context extractor.

**Example Command:**
```bash
python train_diffusion.py \
    --image_folder data/my_hr_images/train \
    --img_size 160 \
    --downscale_factor 4 \
    --epochs 100 \
    --batch_size 8 \
    --accumulation_steps 4 \
    --learning_rate 1e-4 \
    --scheduler_type cosineannealinglr \
    --cosine_t_max_epochs 100 \
    --device cuda:0 \
    --diffusion_mode noise \
    --timesteps 1000 \
    --unet_base_dim 64 \
    --unet_dim_mults 1 2 4 8 \
    --use_attention \
    --rrdb_weights_path checkpoints_rrdb/rrdb_model_nb17_nf64/rrdb_model_best.pth \
    --number_of_rrdb_blocks 17 \
    --rrdb_num_feat 64 \
    --rrdb_gc 32 \
    --base_log_dir ./cv_logs_diffusion \
    --base_checkpoint_dir ./cv_checkpoints_diffusion \
    --exp_name diffusion_refine_bicubic
    # --weights_path_unet cv_checkpoints_diffusion/some_exp/diffusion_model_best.pth # To resume U-Net training
```
**Key Arguments for `train_diffusion.py`:**
* Dataset args: `--image_folder`, `--img_size`, `--downscale_factor`.
* Training loop: `--epochs`, `--batch_size`, `--accumulation_steps`, `--learning_rate`.
* Scheduler: `--scheduler_type` and its related arguments.
* Diffusion: `--timesteps`, `--diffusion_mode` (`noise` or `v_prediction`).
* U-Net: `--unet_base_dim`, `--unet_dim_mults`, `--use_attention`.
* Context RRDBNet: `--rrdb_weights_path` (path to pre-trained RRDBNet), and its configuration (`--number_of_rrdb_blocks`, `--rrdb_num_feat`, `--rrdb_gc`) which **must match** the loaded RRDBNet.
* `--context_type`: Set to `LR` (default) as features are extracted from the LR image.
* Logging/Saving: `--base_log_dir`, `--base_checkpoint_dir`, `--exp_name`, `--weights_path_unet` (for resuming).

#### Pipeline B: Refining RRDBNet Upscaling (using `train_diffusion_predict_rrdb_residual.py`)

This pipeline trains a U-Net to predict the residual (True HR - RRDB-upscaled HR). It uses preprocessed data generated by `utils/preprocess_data_with_rrdb.py`.

**Prerequisites**:
1.  Preprocessed data created by `utils/preprocess_data_with_rrdb.py`. This data includes LR images, HR images, HR images upscaled by a *base RRDBNet*, and features extracted from LR images by a *context RRDBNet*.
2.  The configuration of the *context RRDBNet* used during preprocessing must be known for the U-Net's conditioning.

**Example Command:**
```bash
python train_diffusion_predict_rrdb_residual.py \
    --preprocessed_data_folder preprocessed_data/rrdb_refined_train \
    --val_preprocessed_data_folder preprocessed_data/rrdb_refined_validation \
    --img_size 160 \
    --downscale_factor 4 \
    --apply_hflip \
    --epochs 100 \
    --batch_size 8 \
    --accumulation_steps 4 \
    --learning_rate 1e-4 \
    --scheduler_type cosineannealinglr \
    --cosine_t_max_epochs 100 \
    --device cuda:0 \
    --diffusion_mode noise \
    --timesteps 1000 \
    --unet_base_dim 64 \
    --unet_dim_mults 1 2 4 8 \
    --use_attention \
    --number_of_rrdb_blocks 17 \
    --rrdb_num_feat 64 \
    --rrdb_gc 32 \
    --base_log_dir ./logs_diffusion_v2 \
    --base_checkpoint_dir ./checkpoints_diffusion_v2 \
    --exp_name diffusion_refine_rrdb
    # --weights_path_unet checkpoints_diffusion_v2/some_exp/diffusion_model_best.pth # To resume U-Net training
```
**Key Arguments for `train_diffusion_predict_rrdb_residual.py`:**
* Dataset: `--preprocessed_data_folder` (training data), `--val_preprocessed_data_folder` (validation data, optional).
    * `--img_size`, `--downscale_factor`, `--apply_hflip` relate to how the preprocessed data was created and loaded.
* Training loop & Scheduler: Similar to `train_diffusion.py`.
* Diffusion & U-Net: Similar to `train_diffusion.py`.
* Context RRDBNet Config: `--number_of_rrdb_blocks`, `--rrdb_num_feat`, `--rrdb_gc`. These define the architecture of the U-Net's conditioning projection and **must match the context RRDBNet used during preprocessing with `preprocess_data_with_rrdb.py`** (specifically, the features saved in `lr_features/`).
* `--context`: Set to `LR` (default) for the `DiffusionTrainer`'s internal logic, though the actual conditioning features are pre-loaded.
* Logging/Saving: Similar to `train_diffusion.py`.

## How to Perform Inference

### 1. Inference with Standalone RRDBNet

Use `rrdb_infer.py`. Modify the script to set:
* `model_path`: Path to your trained RRDBNet checkpoint (`.pth`).
* `config`: Dictionary with the RRDBNet configuration (must match training).
* `dataset`: Path to your test images.
* `predict_residual`: Set to `True` if the RRDBNet was trained to predict residuals, `False` otherwise.

**Run:**
```bash
python rrdb_infer.py
```
The script will load a random image from the dataset, perform inference, and plot the LR, HR (ground truth), Bicubic upscaled, and RRDBNet constructed images.

### 2. Inference with Diffusion Model

#### Pipeline A: Refining Bicubic/RRDB Base (using `diffusion_infer.py`)

This script applies a trained U-Net (likely trained via `train_diffusion.py`) to refine an image.
The script currently uses an RRDBNet to get an initial upscaled image (`up_rrdb_img`) and features (`feas`). The U-Net then predicts a residual which is added to `up_rrdb_img`.

**Modify `diffusion_infer.py`:**
* `args.rrdb_weights_path`: Path to the RRDBNet checkpoint (used for base upscaling and feature extraction).
* `config` (for RRDBNet): Must match the loaded RRDBNet.
* `unet = Unet(...)`: Ensure U-Net architecture matches the trained model (e.g., `use_attention`, `rrdb_num_blocks` for conditioning).
* `DiffusionTrainer.load_model_weights(model=unet, model_path=...)`: Path to the trained U-Net checkpoint.
* `ResidualGenerator(..., predict_mode='...')`: `predict_mode` must match U-Net training.
* `args.lr_img_path`: Path to the input low-resolution image.

**Example Run (after script modification):**
```bash
python diffusion_infer.py \
    --lr_img_path data/test_samples/my_lr_image.png \
    --rrdb_weights_path checkpoints_rrdb/rrdb_model_nb17_nf64/rrdb_model_best.pth \
    --unet_weights_path cv_checkpoints_diffusion/diffusion_refine_bicubic/diffusion_model_best.pth \
    --lr_img_size 40 \
    --num_inference_steps 50 \
    --device cuda:0
```
*(Note: `lr_img_size` in `diffusion_infer.py` seems to imply the HR size for the `ResidualGenerator`, calculated as `args.lr_img_size * 4`. The argument name might be confusing.)*

#### Pipeline B: Refining RRDBNet Upscaling (using `diffusion_infer_with_rrdb_residual.py`)

This script applies a U-Net (trained via `train_diffusion_predict_rrdb_residual.py`) to refine an initial HR image generated by a base RRDBNet.

**Example Run:**
```bash
python diffusion_infer_with_rrdb_residual.py \
    --input_hr_image_for_infer data/test_samples/my_hr_image_for_test.png \
    --output_image_path inference_results/refined_output.png \
    --img_size 160 \
    --downscale_factor 4 \
    --rrdb_weights_path_for_base_sr checkpoints_rrdb/base_rrdb_for_sr/rrdb_model_best.pth \
    --rrdb_num_feat_preproc 64 \
    --rrdb_num_block_preproc 17 \
    --rrdb_gc_preproc 32 \
    --rrdb_weights_path_context_extractor checkpoints_rrdb/context_extractor_rrdb/rrdb_model_best.pth \
    --rrdb_num_feat_context 64 \
    --rrdb_num_block_context 17 \
    --rrdb_gc_context 32 \
    --unet_weights_path checkpoints_diffusion_v2/diffusion_refine_rrdb/diffusion_model_best.pth \
    --unet_base_dim 64 \
    --unet_dim_mults 1 2 4 8 \
    --use_attention \
    --diffusion_timesteps 1000 \
    --diffusion_mode noise \
    --diffusion_inference_steps 50 \
    --device cuda:0
```
**Key Arguments for `diffusion_infer_with_rrdb_residual.py`:**
* `--input_hr_image_for_infer`: Path to an HR image (it will be downscaled to create the LR input).
* `--rrdb_weights_path_for_base_sr`: Path to the RRDBNet used to generate the initial HR image. Its config (`--rrdb_num_feat_preproc`, etc.) must match.
* `--rrdb_weights_path_context_extractor`: Path to the RRDBNet used for extracting features to condition the U-Net. Its config (`--rrdb_num_feat_context`, etc.) must match. This should be the same RRDBNet configuration used during the `preprocess_data_with_rrdb.py` step for feature extraction.
* `--unet_weights_path`: Path to the trained U-Net. Its config (`--unet_base_dim`, etc.) must match.
* `--diffusion_mode`: Must match how the U-Net was trained.

## Dependencies

Key Python libraries are listed in `requirements.txt`:
```
diffusers==0.33.1
matplotlib==3.10.3
numpy==2.2.6
opencv_python==4.11.0.86 # opencv-python-headless is also an option
Pillow==11.2.1
torch==2.7.0
torchvision==0.22.0
tqdm==4.67.1
# tensorboard (usually comes with PyTorch or can be installed separately)
```

## Future Work / TODO

* Implement quantitative evaluation metrics (PSNR, SSIM, LPIPS).
* Experiment with different noise schedulers and sampling methods for diffusion models.
* Explore more advanced U-Net architectures or conditioning mechanisms.
* Optimize inference speed (e.g., model quantization, ONNX conversion).
* Develop a more user-friendly interface for inference (e.g., Gradio or Streamlit app).
* Investigate alternative feature extraction networks for conditioning.

## Acknowledgements

* This project builds upon concepts from prominent research in super-resolution and diffusion models.
* Inspired by the paper: "SRDiff: Single Image Super-Resolution with Diffusion Probabilistic Models" by Li, H., Liu, Y., Zhan, F., Lu, S., Xing, E. P., & Miao, C. (2021). ([arXiv:2104.14951](https://arxiv.org/pdf/2104.14951.pdf))
