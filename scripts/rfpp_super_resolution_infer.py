from src.rfpp_modules.inverse_operators import *
from src.rfpp_modules.networks_edm import SongUNet, DhariwalUNet, EDMPrecondVel
from src.utils.rfpp_utils import straightness, parse_config, save_traj
import time
import numpy as np
import glob
from PIL import Image
import matplotlib.pyplot as plt
import json
from torch.nn import DataParallel
from tqdm import tqdm
import argparse
import yaml
from torchvision.utils import save_image
from torchvision import transforms
import os
import torch.nn.functional as F
import torch.nn as nn
import torch
import sys
sys.path.append('.')

@torch.no_grad()
def sample_ode_generative(model, z1, N, arg, use_tqdm=True, solver='euler', label=None, inversion=False,
                          time_schedule=None, sampler='default', operator=None, ref_img_path="", output_dir=""):
    assert solver in ['euler', 'heun']
    assert len(z1.shape) == 4
    assert operator is not None
    assert ref_img_path != ""

    downsample = operator.degradation
    upsample = operator.degradation_transpose

    if inversion:
        assert sampler == 'default'
    tq = tqdm if use_tqdm else lambda x: x

    if solver == 'heun':
        if N % 2 == 0:
            raise ValueError("N must be odd when using Heun's method.")
        N = (N + 1) // 2

    traj = []  # to store the trajectory
    x0hat_list = []
    z1 = z1.detach()
    z = z1.clone()
    batchsize = z.shape[0]

    if time_schedule is not None:
        time_schedule = time_schedule + [0]
        sigma_schedule = [t_ / (1-t_ + 1e-6) for t_ in time_schedule]
        print(f"sigma_schedule: {sigma_schedule}")
    else:
        def t_func(i): return i / N
        if inversion:
            time_schedule = [t_func(i) for i in range(0, N)] + [1]
            time_schedule[0] = 1e-3
        else:
            time_schedule = [t_func(i) for i in reversed(range(1, N+1))] + [0]
            time_schedule[0] = 1-1e-5

    # Load and preprocess image
    image = Image.open(ref_img_path).convert("RGB").resize((64, 64))
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])
    preprocessed = transform(image).unsqueeze(0).to(z1.device)

    # Apply degradation and save
    downsampled = downsample(preprocessed)
    upsampled = upsample(downsampled)
    filename = os.path.splitext(os.path.basename(ref_img_path))[0]
    save_image(upsampled * 0.5 + 0.5,
               os.path.join(output_dir, f"{filename}_degraded.png"))

    config = model.module.config if hasattr(model, 'module') else model.config
    if config["label_dim"] > 0 and label is None:
        label = torch.randint(
            0, config["label_dim"], (batchsize,)).to(z1.device)
        label = F.one_hot(
            label, num_classes=config["label_dim"]).type(torch.float32)

    # Track max GPU memory usage
    torch.cuda.reset_peak_memory_stats()
    start_time = time.time()

    traj.append(z.detach().clone())
    for i in tq(range(len(time_schedule[:-1]))):
        t = torch.ones((batchsize), device=z1.device) * time_schedule[i]
        t_next = torch.ones((batchsize), device=z1.device) * time_schedule[i+1]
        dt = t_next[0] - t[0]

        vt = model(z, t, label)
        x0hat = z - vt * t.view(-1, 1, 1, 1)  # x-prediction

        if solver == 'heun' and i < N - 1:
            z_next = z.detach().clone() + vt * dt
            vt_next = model(z_next, t_next, label)
            vt = (vt + vt_next) / 2
            x0hat = z_next - vt_next * t_next.view(-1, 1, 1, 1)

        x0hat_list.append(x0hat)

        if i < N-1:
            with torch.enable_grad():
                z = z.detach().requires_grad_()
                z_h = z - t[0] * vt

                if arg.likebaseline:
                    z = z.detach() - arg.gradient_scale * (downsample(z_h) - downsampled)
                else:
                    loss = torch.mean(torch.nn.functional.mse_loss(downsample(z_h), downsampled, reduction="none") *
                                      operator.get_mask(shape=downsampled.shape))
                    grads = torch.autograd.grad(loss, z)[0]
                    z = z.detach() - arg.gradient_scale * grads

        z = z.detach().clone() + vt * dt
        traj.append(z.detach().clone())

    end_time = time.time()
    max_memory = torch.cuda.max_memory_allocated() / (1024**2)  # Convert to MB
    total_time = end_time - start_time

    return traj, x0hat_list, max_memory, total_time

def main(inference_config_path='configs/config_rfpp_inference.yaml'):
    # Load inference settings from the YAML file
    with open(inference_config_path, 'r') as f:
        arg_dict = yaml.safe_load(f)
    arg = argparse.Namespace(**arg_dict)

    if not os.path.exists(arg.dir):
        os.makedirs(arg.dir)
    assert arg.config is not None
    config = parse_config(arg.config)
    arg.res = config['img_resolution']
    arg.input_nc = config['in_channels']
    arg.label_dim = config['label_dim']

    # Create directories
    if os.path.exists(os.path.join(arg.dir, "samples")):
        print(
            f"Directory {os.path.join(arg.dir, 'samples')} already exists. Exiting...")
        return

    os.makedirs(os.path.join(arg.dir, "samples"), exist_ok=True)
    os.makedirs(os.path.join(arg.dir, "zs"), exist_ok=True)
    os.makedirs(os.path.join(arg.dir, "trajs"), exist_ok=True)
    os.makedirs(os.path.join(arg.dir, 'tmp'), exist_ok=True)
    os.environ['TMPDIR'] = os.path.join(arg.dir, 'tmp')

    # Initialize model
    model_class = DhariwalUNet if config['unet_type'] == 'adm' else SongUNet
    flow_model = model_class(**config)

    # Setup device
    device_ids = str(arg.gpu).split(',')
    device = torch.device("cuda")
    print(f"Using {'multiple' if len(device_ids) > 1 else ''} GPU {arg.gpu}!")

    pytorch_total_params = sum(p.numel()
                               for p in flow_model.parameters()) / 1000000
    print(f"Total parameters: {pytorch_total_params}M")

    flow_model = EDMPrecondVel(
        flow_model, use_fp16=config.get('use_fp16', False))

    if arg.ckpt is None or not os.path.exists(arg.ckpt):
        raise ValueError(f"Model checkpoint not found or not provided. Please update 'ckpt' in {inference_config_path}")
    flow_model.load_state_dict(torch.load(arg.ckpt, map_location="cpu"))

    if len(device_ids) > 1:
        flow_model = DataParallel(flow_model)
    flow_model = flow_model.to(device).eval()

    if arg.compile:
        flow_model = torch.compile(
            flow_model, mode="reduce-overhead", fullgraph=True)

    # Save configs
    with open(os.path.join(arg.dir, 'config_sampling.json'), 'w') as f:
        json.dump(vars(arg), f, indent=4)

    sample(arg, flow_model, device)


@torch.no_grad()
def sample(arg, model, device):
    output_dir = os.path.join(arg.dir, "samples")
    os.makedirs(output_dir, exist_ok=True)

    # Setup inverse problem
    sampling_config = SamplingConfig()
    sampling_config.inverse_problem = arg.inverse_problem
    sampling_config.noise_sigma = arg.noise_sigma
    # kernel_size, blur_sigma, mask_size are not in the yaml, so we need to handle them.
    sampling_config.kernel_size = arg.kernel_size
    sampling_config.blur_sigma = arg.blur_sigma
    sampling_config.mask_size = arg.mask_size
    sampling_config.scale_factor = arg.scale_factor

    operator = get_inverse_operator(sampling_config, device=device)

    if not os.path.exists(arg.input_dir):
        raise ValueError(f"Input directory not found. Please update 'input_dir' in your config.")

    input_images = sorted(
        glob.glob(os.path.join(arg.input_dir, "*.[pj][np][g]")))
    if not input_images:
        raise ValueError(f"No images found in {arg.input_dir}")
    print(f"Found {len(input_images)} input images")

    straightness_list = []
    nfes = []
    total_times = []
    max_memories = []

    for i, img_path in enumerate(tqdm(input_images)):
        z = torch.randn(arg.batchsize, arg.input_nc,
                        arg.res, arg.res).to(device)

        if arg.label_dim > 0:
            label_onehot = torch.eye(arg.label_dim, device=device)[
                torch.randint(0, arg.label_dim, (z.shape[0],), device=device)]
        else:
            label_onehot = None

        if arg.solver in ['euler', 'heun']:
            t_steps = [float(t) for t in arg.t_steps.split(",")
                       ] if arg.t_steps else None
            if t_steps:
                t_steps[0] = 1-1e-5
            z = z * (1-1e-5)
            traj_uncond, traj_uncond_x0, max_memory, total_time = sample_ode_generative(
                model, z1=z, N=arg.N, arg=arg, use_tqdm=False, solver=arg.solver,
                label=label_onehot, time_schedule=t_steps, sampler=arg.sampler,
                operator=operator, ref_img_path=img_path, output_dir=output_dir
            )
            x0 = traj_uncond[-1]
            uncond_straightness = straightness(traj_uncond, mean=False)
            straightness_list.append(uncond_straightness)
            total_times.append(total_time)
            max_memories.append(max_memory)
        else:
            raise NotImplementedError(f"Solver {arg.solver} not implemented")

        if arg.save_traj:
            save_traj(traj_uncond, os.path.join(
                arg.dir, "trajs", f"{i:05d}_traj.png"))
            save_traj(traj_uncond_x0, os.path.join(
                arg.dir, "trajs", f"{i:05d}_traj_x0.png"))

        for idx in range(len(x0)):
            input_filename = os.path.basename(img_path)
            path_img = os.path.join(arg.dir, "samples", input_filename)
            path_z = os.path.join(
                arg.dir, "zs", input_filename.replace('.png', '.npy'))
            save_image(x0[idx] * 0.5 + 0.5, path_img)

            if arg.save_z:
                np.save(path_z, z[idx].cpu().numpy())

    # Save metrics
    if straightness_list:
        straightness_list = torch.stack(straightness_list).view(-1).cpu().numpy()
        straightness_mean = np.mean(straightness_list).item()
        straightness_std = np.std(straightness_list).item()
        print(f"straightness.shape: {straightness_list.shape}")
        print(
            f"straightness_mean: {straightness_mean}, straightness_std: {straightness_std}")
    else:
        straightness_mean, straightness_std = 0, 0

    nfes_mean = np.mean(nfes) if len(nfes) > 0 else arg.N
    print(f"nfes_mean: {nfes_mean}")
    avg_time = np.mean(total_times)
    avg_memory = np.mean(max_memories)
    print(f"average_time: {avg_time:.2f}s")
    print(f"average_max_memory: {avg_memory:.2f}GB")

    result_dict = {
        "straightness_mean": straightness_mean,
        "straightness_std": straightness_std,
        "nfes_mean": nfes_mean,
        "average_time": avg_time,
        "average_max_memory": avg_memory
    }
    with open(os.path.join(arg.dir, 'result_sampling.json'), 'w') as f:
        json.dump(result_dict, f, indent=4)

    # Plot straightness distribution
    if straightness_list:
        plt.figure()
        plt.hist(straightness_list, bins=20)
        plt.savefig(os.path.join(arg.dir, "straightness.png"))
        plt.close()


if __name__ == "__main__":
    main()